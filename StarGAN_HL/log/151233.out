Namespace(attr_path='data/celeba/list_attr_celeba.txt', batch_size=16, beta1=0.5, beta2=0.999, c2_dim=8, c_dim=5, celeba_crop_size=178, celeba_image_dir='data/celeba/images', d_conv_dim=64, d_lr=0.0005, d_repeat_num=6, dataset='CelebA', g_conv_dim=64, g_lr=0.0005, g_repeat_num=6, image_size=128, lambda_cls=1, lambda_gp=10, lambda_rec=10, log_dir='stargan_celeba/logs', log_step=10, lr_update_step=1000, mode='train', model_save_dir='stargan_celeba/models', model_save_step=2500, n_critic=5, num_iters=200000, num_iters_decay=30000, num_workers=1, rafd_crop_size=256, rafd_image_dir='data/RaFD/train', result_dir='stargan_celeba/results', resume_iters=None, sample_dir='stargan_celeba/samples', sample_step=1000, selected_attrs=['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young'], test_iters=50000, use_tensorboard=True)
Finished preprocessing the CelebA dataset...
Generator(
  (main): Sequential(
    (0): Conv2d(8, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): ResidualBlock(
      (main): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU(inplace=True)
    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): ReLU(inplace=True)
    (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
    (22): Tanh()
  )
)
G
The number of parameters: 8430528
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (3): LeakyReLU(negative_slope=0.01)
    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): LeakyReLU(negative_slope=0.01)
    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (9): LeakyReLU(negative_slope=0.01)
    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (11): LeakyReLU(negative_slope=0.01)
  )
  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (conv2): Conv2d(2048, 5, kernel_size=(2, 2), stride=(1, 1), bias=False)
)
D
The number of parameters: 44762048
2020-11-06 02:29:04.597296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-06 02:29:04.604885: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500030000 Hz
2020-11-06 02:29:04.605121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568c428f900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-06 02:29:04.605142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Start training...
/usr/itetnas04/data-scratch-01/dlim_08hs20/data/conda_envs/dlim/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Elapsed [1:31:23], Iteration [10/200000], D/loss_real: -13.0834, D/loss_fake: -11.4318, D/loss_cls: 3.1355, D/loss_gp: 2.1760, G/loss_fake: 5.1605, G/loss_rec: 0.5749, G/loss_cls: 2.9579
Elapsed [3:03:27], Iteration [20/200000], D/loss_real: -10.3938, D/loss_fake: -0.4881, D/loss_cls: 2.6703, D/loss_gp: 0.1173, G/loss_fake: 2.8506, G/loss_rec: 0.5486, G/loss_cls: 3.5182
Elapsed [4:35:03], Iteration [30/200000], D/loss_real: 1.0434, D/loss_fake: -12.0763, D/loss_cls: 3.1761, D/loss_gp: 0.1683, G/loss_fake: 16.6280, G/loss_rec: 0.5738, G/loss_cls: 2.6374
Elapsed [6:04:30], Iteration [40/200000], D/loss_real: 17.9307, D/loss_fake: -36.2796, D/loss_cls: 4.9726, D/loss_gp: 1.6954, G/loss_fake: -63.7698, G/loss_rec: 0.5167, G/loss_cls: 9.0792
Elapsed [7:34:02], Iteration [50/200000], D/loss_real: 1.9323, D/loss_fake: -4.0957, D/loss_cls: 3.2941, D/loss_gp: 0.4994, G/loss_fake: 4.6134, G/loss_rec: 0.5305, G/loss_cls: 3.0916
Elapsed [9:06:08], Iteration [60/200000], D/loss_real: 17.8783, D/loss_fake: -27.5786, D/loss_cls: 2.9391, D/loss_gp: 0.4200, G/loss_fake: 2.8027, G/loss_rec: 0.4702, G/loss_cls: 3.6871
Elapsed [10:38:13], Iteration [70/200000], D/loss_real: -36.4884, D/loss_fake: 32.6472, D/loss_cls: 2.5398, D/loss_gp: 0.8789, G/loss_fake: 36.2969, G/loss_rec: 0.4494, G/loss_cls: 2.3292
Elapsed [12:10:23], Iteration [80/200000], D/loss_real: 0.7474, D/loss_fake: -6.1767, D/loss_cls: 3.1561, D/loss_gp: 0.0446, G/loss_fake: 4.3303, G/loss_rec: 0.4601, G/loss_cls: 2.9798
Elapsed [13:41:53], Iteration [90/200000], D/loss_real: -8.9324, D/loss_fake: 3.3625, D/loss_cls: 3.0574, D/loss_gp: 0.2179, G/loss_fake: -25.1695, G/loss_rec: 0.4540, G/loss_cls: 2.9651
Elapsed [15:14:11], Iteration [100/200000], D/loss_real: -4.8806, D/loss_fake: -0.7400, D/loss_cls: 3.3548, D/loss_gp: 0.7096, G/loss_fake: -5.6195, G/loss_rec: 0.4640, G/loss_cls: 3.2335
Elapsed [16:45:04], Iteration [110/200000], D/loss_real: -7.4194, D/loss_fake: 5.9405, D/loss_cls: 3.1916, D/loss_gp: 0.0069, G/loss_fake: 4.3295, G/loss_rec: 0.4682, G/loss_cls: 2.9479
Elapsed [18:14:31], Iteration [120/200000], D/loss_real: -49.0438, D/loss_fake: 23.4877, D/loss_cls: 3.6383, D/loss_gp: 1.5544, G/loss_fake: 12.5127, G/loss_rec: 0.4719, G/loss_cls: 3.2790
Elapsed [19:45:16], Iteration [130/200000], D/loss_real: -44.6457, D/loss_fake: 21.6956, D/loss_cls: 3.2361, D/loss_gp: 0.3806, G/loss_fake: -23.5769, G/loss_rec: 0.4871, G/loss_cls: 2.8641
Elapsed [21:15:35], Iteration [140/200000], D/loss_real: 17.8401, D/loss_fake: -30.0088, D/loss_cls: 2.6396, D/loss_gp: 0.5461, G/loss_fake: 6.0529, G/loss_rec: 0.4309, G/loss_cls: 2.7251
Elapsed [22:45:50], Iteration [150/200000], D/loss_real: -10.2998, D/loss_fake: -4.8694, D/loss_cls: 2.5556, D/loss_gp: 1.7931, G/loss_fake: 7.4203, G/loss_rec: 0.4016, G/loss_cls: 2.6151
slurmstepd: error: *** JOB 151233 ON bmicgpu01 CANCELLED AT 2020-11-07T02:28:59 DUE TO TIME LIMIT ***
